{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_cuda.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6EV7B2cEDPT",
        "colab_type": "code",
        "outputId": "858b7917-6044-4da6-fa31-c87afe1f96f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-tg637rll\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-tg637rll\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=cd34a005bc3c375e2c0413bb272a16002467623db5035cf12005cea79867893e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-711gx63e/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJiW-KZAadH9",
        "colab_type": "text"
      },
      "source": [
        "Codigo - Lanzamiento del kernel 6 con memoria compartida y memoria bidimensional\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M8uA2erxPku",
        "colab_type": "code",
        "outputId": "07c9f653-f279-40ed-d512-9eb2f3dd8a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%%cu\n",
        "#include <assert.h> \n",
        "#include <cuda_runtime.h> \n",
        "#include <device_functions.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <stdio.h> \n",
        "\n",
        "__global__ void SumaColMatrizKernel_0(int M, int N, float* Md, float* Nd){\n",
        "    // Pvalue es usado para el valor intermedio\n",
        "    int Pvalue = 0;\n",
        "    int columna = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int posIni = columna * M;\n",
        "        for (int k = 0; k < M; ++k) {\n",
        "            Pvalue = Pvalue + Md[posIni + k];\n",
        "        }\n",
        "    Nd[columna] = Pvalue;\n",
        "}\n",
        "\n",
        "__global__ void SumaColMatrizKernel_1(int M, float* Md, float* Nd)\n",
        "{\n",
        "    // Pvalue es usado para el valor intermedio\n",
        "    int Pvalue = 0;\n",
        "    int columna = threadIdx.x;\n",
        "    int posIni = columna * M;\n",
        "    for (int k = 0; k < M; ++k) {\n",
        "        for (int k =\n",
        "            0; k < M; ++k) {\n",
        "            Pvalue = Pvalue + Md[posIni + k];\n",
        "        }\n",
        "        Nd[columna] = Pvalue;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void SumaColMatrizKernel_2(int M, int N, float* Md, float* Nd)\n",
        "{\n",
        "    // Pvalue es usado para el valor intermedio\n",
        "    int Pvalue = 0;\n",
        "    int columna = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int posIni = columna * M;\n",
        "        for (int k = 0; k < M; ++k) {\n",
        "            Pvalue = Pvalue + Md[posIni + k];\n",
        "        }\n",
        "    Nd[columna] = Pvalue;\n",
        "}\n",
        "\n",
        "__global__ void SumaColMatrizKernel_3(int M, float* Md, float* Nd)\n",
        "{\n",
        "    // Pvalue es usado para el valor intermedio\n",
        "    int Pvalue = 0;\n",
        "    int columna = blockIdx.x;\n",
        "    int pasos = M / blockDim.x;\n",
        "    int posIni = columna * M + threadIdx.x * pasos;\n",
        "    for (int k = 0; k < pasos; ++k) {\n",
        "        Pvalue = Pvalue + Md[posIni + k];\n",
        "    }\n",
        "    atomicAdd(&(Nd[columna]), Pvalue);\n",
        "}\n",
        "\n",
        "// Lanzamiento del kernel 4 con memoria bidimensional\n",
        "__global__ void SumaColMatrizKernel_4(int M, int N, float* Md, float* Nd)\n",
        "{\n",
        "    // Pvalue es usado para el valor intermedio\n",
        "    int Pvalue = 0;\n",
        "    int columna = blockIdx.y * (N / gridDim.x) + threadIdx.x;\n",
        "    int pasos = M / blockDim.x;\n",
        "    int posIni = columna * M + threadIdx.x * pasos;\n",
        "    for (int k = 0; k < pasos; ++k) {\n",
        "        Pvalue = Pvalue + Md[posIni + k];\n",
        "    }\n",
        "    atomicAdd(&(Nd[columna]), Pvalue);\n",
        "}\n",
        "\n",
        "// Lanzamiento del kernel 5 con memoria compartida  \n",
        "#define DIMBLOCKX 32\n",
        "__global__ void SumaColMatrizKernel_5(int M, float* Md, float* Nd)\n",
        "{\n",
        "    __shared__ float Nds[DIMBLOCKX];\n",
        "    int Pvalue = 0;\n",
        "    int columna = blockIdx.x;\n",
        "    int pasos = M / blockDim.x;\n",
        "    int posIni = columna * M + threadIdx.x * pasos;\n",
        "    for (int k = 0; k < pasos; ++k) {\n",
        "        Pvalue = Pvalue + Md[posIni + k];\n",
        "    }\n",
        "    atomicAdd(&(Nd[columna]), Pvalue);\n",
        "    // Nds[threadIdx.x] = Pvalue;\n",
        "\n",
        "    __syncthreads();\n",
        "    if (threadIdx.x == 0)\n",
        "    {\n",
        "        for (int i = 1; i < blockDim.x; ++i) {\n",
        "            Nds[0] = Nds[0] + Nds[i];\n",
        "        }\n",
        "        atomicAdd(&(Nd[blockIdx.y]), Nds[0]);\n",
        "        // Nd[blockIdx.y] = Nds[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Lanzamiento del kernel 6 con memoria compartida y memoria bidimensional \n",
        "#define DIMBLOCKX 32\n",
        "__global__ void SumaColMatrizKernel_6(int M, float* Md, float* Nd)\n",
        "{\n",
        "    // Pvalue es usado para el valor intermedio\n",
        "    float Pvalue = 0;\n",
        "    int columna = threadIdx.x;\n",
        "    int posIni = columna*M;\n",
        "    for (int k = 0; k < M; ++k) {\n",
        "      Pvalue = Pvalue + Md[posIni+k];\n",
        "    }\n",
        "    Nd[columna] = Pvalue;\n",
        "  }\n",
        "\n",
        "void SumaColMatriz(int M, int N, float* Mh, float* Nh)\n",
        "{\n",
        "    int size = M*N*sizeof(float), size2=N*sizeof(float);\n",
        "    float* Md, * Nd;\n",
        "\n",
        "    // Asignar en dispositivo\n",
        "    cudaMalloc(&Md, size);\n",
        "    cudaMalloc(&Nd, size2);\n",
        "\n",
        "    // Inicializo matrices en el dispositivo\n",
        "    cudaMemcpy(Md, Mh, size,  cudaMemcpyHostToDevice);\n",
        "    cudaMemset(Nd, 0, size2);\n",
        "    // Invocar el kernel que suma en GPU\n",
        "\n",
        "    /*--------- KERNEL 0 ---------*/\n",
        "    // SumaColMatrizKernel_0 <<<N, 1 >>> (M, Md, Nd);\n",
        "\n",
        "    /*--------- KERNEL 1 ---------*/\n",
        "    // SumaColMatrizKernel_1 <<<1, N >>> (M, Md, Nd);\n",
        "    // dim3 tamGrid(1, 1); //Grid dimensión\n",
        "    // dim3 tamBlock(N, 1, 1); //Block dimensión\n",
        "    // SumaColMatrizKernel_1 <<<1, N >>> (M, Md, Nd);\n",
        "\n",
        "    /*--------- KERNEL 2 ---------*/\n",
        "    // int bloques = N / 128; // se asume N múltiplo de 128\n",
        "    // dim3 tamGrid(bloques, 1); //Grid dimensión\n",
        "    // dim3 tamBlock(128, 1, 1); //Block dimensión\n",
        "    // SumaColMatrizKernel_2 <<<bloques, 128 >>> (M, Md, Nd);\n",
        "\n",
        "    /*--------- KERNEL 3 ---------*/\n",
        "    // int chunk = 32; // Se asume M múltiplo de 32\n",
        "    // dim3 tamGrid(N / chunk, 1); //Grid dimensión\n",
        "    // dim3 tamBlock(M / chunk, chunk, 1); //Block dimensión\n",
        "    // SumaColMatrizKernel_3 <<<N, M / chunk >>> (M, Md, Nd);\n",
        "\n",
        "    // Lanzamiento del kernel 4 con memoria bidimensional\n",
        "    /*--------- KERNEL 4 ---------*/\n",
        "    /* Si quiero que un bloque procese más de una columna */\n",
        "    // int chunk = 32; // Se asume M y N múltiplos de 32\n",
        "    // dim3 tamGrid(N / chunk, 1); //Grid dimensión\n",
        "    // dim3 tamBlock(M / chunk, chunk, 1); //Block dimensión\n",
        "    // SumaColMatrizKernel_4 <<<tamGrid, tamBlock >>> (M, N, Md, Nd);\n",
        "\n",
        "    // Lanzamiento del kernel 5 con memoria compartida\n",
        "    /*--------- KERNEL 5 ---------*/\n",
        "    /* configuración de la ejecución */\n",
        "    // int chunk = 32;\n",
        "    // dim3 tamGrid(N, 1); //Grid dimensión\n",
        "    // dim3 tamBlock(M / chunk, 1, 1); //Block dimensión\n",
        "    // SumaColMatrizKernel_5 <<<tamGrid, tamBlock >>> (M, Md, Nd); /* lanzamiento del kernel */\n",
        "\n",
        "    // Lanzamiento del kernel 6 con memoria compartida y memoria bidimensional\n",
        "    /*--------- KERNEL 6 ---------*/\n",
        "    /* configuración de la ejecución */\n",
        "    int chunk = 32;\n",
        "    dim3 tamGrid(1,1);\n",
        "    dim3 tamBlock(N,1,1);\n",
        "    SumaColMatrizKernel_6 <<<tamGrid, tamBlock>>>(M, Md, Nd);\n",
        "\n",
        "    /*--------- TRAER RESULTADO ---------*/\n",
        "    // Traer resultado;\n",
        "    cudaMemcpy(Nh, Nd, size2, cudaMemcpyDeviceToHost);\n",
        "    for (int i=0; i<N; i++)\n",
        "      std::cout<<Nh[i]<<\" \";\n",
        "    cudaFree(Md); // Free matrices en device\n",
        "    cudaFree(Nd); // Free matrices en device\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    int M =1024;\n",
        "    int N =512;\n",
        "    float *Mh = new float[M*N];\n",
        "    float *Nh = new float[N];\n",
        "    \n",
        "    for (int i=0; i<M; i++)\n",
        "      for (int j=0; j<N; j++)\n",
        "        Mh[i*N+j] = 1;\n",
        "\n",
        "    SumaColMatriz(M,N,Mh,Nh);\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
